{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f996132",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "\n",
    "# Ensure CUDA support is available \n",
    "if torch.cuda.is_available(): \n",
    "    \n",
    "# Perform operations on GPU \n",
    "    device = torch.device(\"cuda\") # ... \n",
    "# Clear CUDA memory \n",
    "    torch.cuda.empty_cache() \n",
    "else: \n",
    "    print(\"CUDA is not available.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cea0ee3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97eca4b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "from typing import Any, List, Tuple\n",
    "import numpy as np\n",
    "import torch\n",
    "from numpy import ndarray\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import AutoModelForSequenceClassification, BatchEncoding, AutoTokenizer, PreTrainedTokenizerBase\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07bf0063",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentimentDataset(Dataset):\n",
    "    def __init__(self, texts, tokenizer, max_length):\n",
    "        self.texts = texts\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        text = self.texts[item]\n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_length,\n",
    "            return_token_type_ids=False,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt',\n",
    "        )\n",
    "        return {\n",
    "            'text': text,\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten()\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2fd7435",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = 'needed_e5_large'  # Replace with your model path\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_path)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3a2fb1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('combined_reviews.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "840b039f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class MyTextDataset(Dataset):\n",
    "    def __init__(self, sentence_list: List[str]) -> None:\n",
    "        self.sentences = sentence_list\n",
    "    \n",
    "    def __len__(self) -> int:\n",
    "        return len(self.sentences)\n",
    "    \n",
    "    def __getitem__(self, idx: int) -> Tuple[int, str]:\n",
    "        return idx, self.sentences[idx]\n",
    "\n",
    "class MyCollateBatch:\n",
    "    def __init__(self, tokenizer: PreTrainedTokenizerBase) -> None:\n",
    "        self.tokenizer = tokenizer\n",
    "    \n",
    "    def __call__(self, batch: List[Tuple[int, str]]) -> BatchEncoding:\n",
    "        sentences = [b[1] for b in batch]\n",
    "        idx = [b[0] for b in batch]\n",
    "        text = self.tokenizer(sentences, max_length=512, padding=\"max_length\", truncation=True, return_tensors=\"pt\")\n",
    "        text[\"idx\"] = idx\n",
    "        return text\n",
    "\n",
    "class ModelSentiment:\n",
    "    def __init__(self, model_folder: str, device: torch.device) -> None:\n",
    "        self.device = device\n",
    "        self.model_folder = model_folder\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_folder)\n",
    "        self.model = AutoModelForSequenceClassification.from_pretrained(model_folder, return_dict=True)\n",
    "        self.collate_fn = MyCollateBatch(self.tokenizer)\n",
    "        self.model.to(device)\n",
    "        self.model.eval()\n",
    "    \n",
    "    def __call__(self, sentence_list: List[str]):\n",
    "        data_ds = MyTextDataset(sentence_list)\n",
    "        loader = DataLoader(data_ds, batch_size=1, collate_fn=self.collate_fn)\n",
    "        result = np.zeros((len(sentence_list), len(self.class_names())))\n",
    "        print('Processing sentences...')\n",
    "        for batch in tqdm(loader):\n",
    "            idx = batch[\"idx\"]\n",
    "            batch = {k: v.to(self.device) for k, v in batch.items() if k != \"idx\"}\n",
    "            with torch.no_grad():\n",
    "                outputs = self.model(**batch)\n",
    "                logits = outputs.logits\n",
    "                predictions = torch.softmax(logits, dim=-1)\n",
    "                result[idx, :] = predictions.to(\"cpu\").numpy()\n",
    "        return result\n",
    "    \n",
    "    def class_names(self) -> Any:\n",
    "        return self.model.config.id2label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5640e58d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pre-trained model\n",
    "model_folder = \"needed_e5_large\"  # Update this to your model folder path\n",
    "device = torch.device('cuda')\n",
    "model_sentiment = ModelSentiment(model_folder, device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "141cf220",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b7356df",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf946890",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the text data from the 'Review' column\n",
    "reviews = df['Review'].astype(str).tolist()\n",
    "reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e093cad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model_sentiment(reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e9e1cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Sentiment'] = np.argmax(predictions, axis=1)\n",
    "df['Confidence'] = np.max(predictions, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5294da5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_csv_path = 'sentiment_results.csv'\n",
    "df.to_csv(output_csv_path, index=False)\n",
    "\n",
    "print(f\"Sentiment analysis results saved to {output_csv_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
